{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3: Exploring other denoiser architecture\n",
    "\n",
    "\n",
    "In this lesson we will introduce the *layer inspectors*, tools for inspecting the intermediate state of a network and use it to study DnCNN. Then we will apply it analize a multiscale denoising network called U-Net. Finally we will study a network architectures inspired on variational methods.\n",
    "\n",
    "We will cover the following topics:\n",
    "* Peeking inside the DnCNN network with layer inspectors  \n",
    "* U-Net architecture - with and without skip connections\n",
    "* What can we see by applying the layer inspector to U-net?\n",
    "* Strangling networks\n",
    "\n",
    "There are **5 questions** in the notebook and corresponding text areas to fill-in the answers. \n",
    "\n",
    "\n",
    "#### Instructions\n",
    "To solve this TP, answer the questions below. Then export the notebook with the answers using  the menu option **File->Download as->HTML**. Send the resulting *html* file by mail to [facciolo@cmla.ens-cachan.fr](mailto:facciolo@cmla.ens-cachan.fr) with subject \"Report tp1 of SURNAME, Name\", by 30/11/2018.  You will receive an acknowledgement of receipt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup code for the notebook\n",
    "\n",
    "# Execute code 'cells' like this by clicking on the 'Run' \n",
    "# button or by pressing [shift] + [Enter].\n",
    "\n",
    "# This cell only imports some python packages that will be\n",
    "# used below. It doesn't generate any output. Something similar \n",
    "# applies to the next two or three cells. They only define \n",
    "# functions that are used later.\n",
    "\n",
    "\n",
    "# This notebook can also run on colab (https://colab.research.google.com/)\n",
    "# The following lines install the necessary packages in the colab environment\n",
    "try:\n",
    "    from google.colab import files\n",
    "    !pip install torch==0.4.1\n",
    "    !pip install torchvision\n",
    "    !pip install Pillow==4.0.0\n",
    "    !pip install scikit-image\n",
    "    !pip install hdf5storage\n",
    "\n",
    "    !rm -fr MVAdenoising2018\n",
    "    !git clone  https://github.com/gfacciol/MVAdenoising2018\n",
    "    !cp -r MVAdenoising2018/* .\n",
    "\n",
    "except ImportError:\n",
    "    # %matplotlib notebook\n",
    "    pass\n",
    "\n",
    "\n",
    "# These are all the includes used through the notebook\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import vistools          # image visualization toolbox\n",
    "from   skimage import io # read and write images\n",
    "from   vistools import unzip\n",
    "\n",
    "\n",
    "# global variable for setting the torch.load    map_location\n",
    "if torch.cuda.is_available():\n",
    "    loadmap = {'cuda:0': 'gpu', 'location': 'gpu'}\n",
    "else:\n",
    "    loadmap = {'cuda:0': 'cpu', 'location': 'cpu'}\n",
    "    \n",
    "\n",
    "#%matplotlib notebook\n",
    "# Autoreload external python modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Peeking inside the DnCNN network with layer inspectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will introduce layer inspectors to see the intermediate results for the hidden layers of a network. We define a layer inspector as the simplest affine transformation (convolutional) that takes a hidden layer and produces an output image. In DnCNN, each layer inspectors are $1\\times 1$ convolutional layers that take the features at a given layer and produce a single image. These inspectors have to be trained. We will trained them *after* DnCNN was trained.\n",
    "\n",
    "Below we define an inspector module `DnCNNInspector`, which receives a trained DnCNN network  $\\mathcal F$ as input. For each layer of DnCNN we add an inpector layer, which we'll denote by $\\mathcal I^l_{\\theta}$. The inspector is applied to the output of layer $l$ of the denoising network $\\mathcal F$. We will denote that output $\\mathcal F^l(u)$, where $u$ is the input image.\n",
    "\n",
    "Note that we only train the parameters of the inspectors. We prevent training the parameters of the input network, by setting their `require_grad` field to false with the following lines:\n",
    "\n",
    "``` python\n",
    "        # we don't want to train the dncnn parameters\n",
    "        for p in self.dncnn.parameters():\n",
    "            p.requires_grad = False\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models import DnCNN\n",
    "\n",
    "class DnCNNInspector(nn.Module):\n",
    "    def __init__(self, dncnn):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            - dncnn: a dncnn network\n",
    "        \"\"\"\n",
    "        super(DnCNNInspector, self).__init__()\n",
    "            \n",
    "        # retrieve parameters of dncnn network\n",
    "        self.num_layers   = len(dncnn.layers)\n",
    "        self.num_features = dncnn.layers[0].conv.weight.shape[0]\n",
    "        self.kernel_size  = dncnn.layers[0].conv.weight.shape[2]\n",
    "        self.out_channels = dncnn.layers[-1].weight.shape[0]\n",
    "        self.in_channels  = dncnn.layers[0].conv.weight.shape[1]\n",
    "        self.residual     = dncnn.residual\n",
    "        \n",
    "        import copy\n",
    "        self.dncnn = copy.deepcopy(dncnn)\n",
    "        \n",
    "        # we don't want to train the dncnn parameters\n",
    "        for p in self.dncnn.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # define inspector layers\n",
    "        self.inspectors = []\n",
    "        for i in range(self.num_layers-1):\n",
    "            self.inspectors.append(nn.Conv2d(self.num_features,\n",
    "                                             self.out_channels,\n",
    "                                             1)) # <-- 1x1 kernel\n",
    "            name = 'inspector%d' % i\n",
    "            self.register_parameter(name + 'weight', self.inspectors[i].weight)\n",
    "            self.register_parameter(name + 'bias'  , self.inspectors[i].bias)\n",
    "\n",
    "   \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # force eval mode in dncnn network\n",
    "        self.dncnn.eval()\n",
    "\n",
    "        outputs = []\n",
    "        out = x\n",
    "        for i in range(self.num_layers-1):\n",
    "            # apply layer of dncnn\n",
    "            out = self.dncnn.layers[i](out)\n",
    "            \n",
    "            # apply inspector\n",
    "            if self.residual:\n",
    "                outputs.append(x - self.inspectors[i](out))\n",
    "            else:\n",
    "                outputs.append(self.inspectors[i](out))\n",
    "\n",
    "        # returns a tensor having all the produced outputs as channels\n",
    "        # the number of channels is (num_layers-1)*ch, where ch is the \n",
    "        # number of channels of x\n",
    "        return torch.cat(outputs,-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To train the inspectors we need a custom loss (because the inspector network produces multiple output images). The following block defines our `multiOutputMSELoss`. Our loss will be the MSE between the images produced by each inspector and the clean image:\n",
    "$$R^{\\text{emp}}(\\theta) = \\frac 1{L-1}\\sum_i \\sum_{l=1}^{l = L-1} \\|\\mathcal I^l_\\theta(\\mathcal F^l(u)) - \\widetilde u\\|^2.$$\n",
    "The parameters $\\theta$ here are the weights and biases of each inspector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# we define this loss, so that we can train all inspectors in parallel\n",
    "def multiOutputMSELoss(x, y):\n",
    "    \"\"\"\n",
    "    Computes the average MSE loss multiple outputs x_1, ...., x_n with respect\n",
    "    to a single target y.\n",
    "    \n",
    "    Args:\n",
    "        - x: outputs, 4D tensor of size [b, n*ch, w, h] where b is the batch size, n is\n",
    "             the number of ouputs, ch is the number of channels of each output and wxh\n",
    "             their spatial dimension\n",
    "        - y: target, 4D tensor of size [b, ch, w, h]\n",
    "    \n",
    "    Returns:\n",
    "        - loss: average MSE loss, i.e. 1/n * \\sum_i MSELoss(x_i,y)\n",
    "    \"\"\"\n",
    "    \n",
    "    if x.shape[-3] % y.shape[-3] != 0:\n",
    "        print('multiOutputMSELoss: x num. of channels is not a multiple of y num. of channels')\n",
    "    n = x.shape[-3]//y.shape[-3]\n",
    "    \n",
    "    return ((x - torch.cat([y]*n,1))**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are now ready to train our inspectors. In the following blocks we train and apply the instector network to peack inside DnCNN by displaying the intermediate results thoughout the network for image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train layer inspectors by minimizing the multi output MSE loss\n",
    "\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "from models import DnCNN, DnCNN_pretrained\n",
    "\n",
    "sigma=30\n",
    "\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "if training:\n",
    "\n",
    "    # data\n",
    "    trainloader, validationloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=40, \n",
    "                                               train_batch_size=128)\n",
    "\n",
    "    # load a dncnn network, and build an inspector for it\n",
    "    #dncnn = torch.load('trainings/tiny_DnCNN_mse_2000.pt', map_location=loadmap))[0]\n",
    "    dncnn = DnCNN_pretrained(sigma)\n",
    "    dncnn_ins = DnCNNInspector(dncnn)\n",
    "\n",
    "    # run the training loop\n",
    "    dncnn_ins, losst, lossv, = trainmodel(dncnn_ins, multiOutputMSELoss, trainloader, validationloader, \n",
    "                                         num_epochs=100, save_every=100, loss_every=10,  \n",
    "                                         learning_rate=0.01, weight_decay=0.00001,\n",
    "                                         filename='pre-trained-tp3/layer_inspector_DnCNN_')\n",
    "\n",
    "else:\n",
    "    dncnn_ins, _, losst, lossv = torch.load('pre-trained-tp3/layer_inspector_DnCNN_0100.pt', map_location=loadmap)\n",
    "\n",
    "# plot loss\n",
    "plt.semilogy(lossv, label='val')\n",
    "plt.semilogy(losst, label='train')\n",
    "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from denoising_helpers import PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "# test it with a noisy image\n",
    "sigma=30\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "\n",
    "# put the image in the range [0,1] and add noise\n",
    "im_noisy = im_noisy.astype('float32') / 255.\n",
    "\n",
    "# create inpector from existing dncnn\n",
    "dncnn = DnCNN_pretrained(sigma)\n",
    "\n",
    "# torch data type\n",
    "dtype = torch.FloatTensor\n",
    "if torch.cuda.is_available():\n",
    "    # run on GPU\n",
    "    dncnn_ins = dncnn_ins.cuda()\n",
    "    dncnn = dncnn.cuda()\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# set denoising network in evaluation (inference) mode\n",
    "dncnn_ins.eval()\n",
    "dncnn.eval()\n",
    "\n",
    "# apply inspector network\n",
    "with torch.no_grad(): # tell pytorch that we don't need gradients\n",
    "    img = dtype(im_noisy[np.newaxis,np.newaxis,:,:]) # convert to tensor\n",
    "    out  = dncnn(img).cpu()\n",
    "    outs = dncnn_ins(img).cpu()\n",
    "\n",
    "out_ims = list()\n",
    "for i in range(outs.shape[1]):\n",
    "    out_ims.append( (outs[0,i,:,:]*255, 'inspector %d - PSNR = %f' %(i, PSNR(outs[0,i,:,:]*255, im_clean))) )    \n",
    "\n",
    "out_ims.append( (out*255, 'output - PSNR = %f' %(PSNR(out*255, im_clean))))\n",
    "out_ims.append( (im_noisy*255, 'noisy - PSNR = %f' %(PSNR(im_noisy*255, im_clean))))\n",
    "    \n",
    "# show as a gallery\n",
    "vistools.display_gallery(unzip(out_ims,0), unzip(out_ims,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question 1.**  Comment on the intermediate results on the network. Compare the outputs of the layers with the last ones. Does the PSNR increase through the network?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ANSWER TO QUESTION 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now study the U-Net instroduced in the context of image segmentation in\n",
    "\n",
    "    O. Ronneberger, P. Fischer, T. Brox, \"U-Net: Convolutional Networks for Biomedical Image Segmentation,\" Medical Image Computing and Computer-Assisted Intervention (MICCAI), Springer, LNCS, Vol.9351: 234--241, 2015\n",
    "\n",
    "and used in the context of image restoration in: [C. Chen, Q. Chen, J. Xu, V. Koltun, \"Learning to See in the Dark,\"](https://arxiv.org/abs/1805.01934)\n",
    " \n",
    "The U-Net has a U-shaped architecture as illustrated below:\n",
    "\n",
    "<img width=500 src=\"https://raw.githubusercontent.com/gfacciol/MVAdenoising2018/master/models/unet.png\"/>\n",
    "\n",
    "The definition of our U-Net is `models.UNet`. The following code trains it (or loads a pre-trained one)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from models import UNet\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "\n",
    "\n",
    "sigma=30\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "\n",
    "# choose loss\n",
    "#loss_name = 'l1'\n",
    "loss_name = 'l2'\n",
    "\n",
    "if training:\n",
    "    \n",
    "    # data\n",
    "    trainloader, valloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=128, \n",
    "                                               train_batch_size=45 )\n",
    "\n",
    "    # network model\n",
    "    denoiser = UNet(1,1)    \n",
    "\n",
    "    # run the training loop using chosen loss\n",
    "    loss_fn = nn.L1Loss() if loss_name == 'l1' else nn.MSELoss()\n",
    "    denoiser, losst, lossv, = trainmodel(denoiser, loss_fn, trainloader, valloader, \n",
    "                                         num_epochs=2000, save_every=500, loss_every=10,  \n",
    "                                         learning_rate=0.001, weight_decay=0.00001,\n",
    "                                         filename='pre-trained-tp3/Unet_%s_' % (loss_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import torch\n",
    "from models import UNet\n",
    "from denoising_helpers import test_denoiser\n",
    "\n",
    "denoiser, _, losst, lossv = torch.load('pre-trained-tp3/Unet_l2_2000.pt', map_location=loadmap)[0:4]\n",
    "\n",
    "plt.semilogy(lossv, '.-', label='net1 val')\n",
    "plt.semilogy(losst, '.-', label='net1 train')\n",
    "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss');\n",
    "plt.show()\n",
    "\n",
    "denoiser.cpu()\n",
    "\n",
    "img_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "\n",
    "_ = test_denoiser(denoiser, img_clean, sigma=30, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question 2.** \n",
    "In the block below, write the code needed for comparing the performance of U-Net with DnCNN, and FFDNet. Compare speed, PSNR, and visual quality. \n",
    "\n",
    "**Tips**\n",
    "* Follow the comments below and re-use code from other blocks (from previous TPs)\n",
    "* To measure the execution time you can use the command :  ```%timeit  output = command(input)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "###############################\n",
    "###   ANSWER TO QUESTION 2  ###\n",
    "###############################\n",
    "\n",
    "from skimage import io\n",
    "import torch\n",
    "from models import UNet, DnCNN_pretrained, DnCNN, FFDNet_pretrained_grayscale, FFDNet\n",
    "from denoising_helpers import test_denoiser\n",
    "\n",
    "sigma = 30\n",
    "\n",
    "# load image\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "\n",
    "# list of labelled results to display as gallery\n",
    "outputs = list()\n",
    "\n",
    "\n",
    "# let's load U-Net first ###############################################\n",
    "\n",
    "# load network\n",
    "denoiser = torch.load( # TODO file with pretrained U-Net # )[0]\n",
    "denoiser.cpu()\n",
    "    \n",
    "# denoise image with loaded net\n",
    "out = test_denoiser(denoiser, im_noisy, None, has_noise=True)[0] \n",
    "outputs.append( (out, 'U-Net - PSNR = %f' %(PSNR(out, im_clean))) )    \n",
    "\n",
    "# TODO now test DnCNN_pretrained #################################\n",
    "\n",
    "# TODO finally FFDNet_pretrained_grayscale #################################\n",
    "\n",
    "    \n",
    "# show as a gallery\n",
    "vistools.display_gallery(unzip(outputs,0), unzip(outputs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Layer inspector for U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "U-Net downscales the image through the network. To inpect these downscaled layers, we need our inpectors to up-scale them. One way of doing that is by transposing a convolutional layer with a stride. A convolutional layer with a stride of 2, produces an output which is half the size of the input. Thus by transposing it, we produce an output which has twice the input size.\n",
    "\n",
    "In the next block we define our `UNetInspector` module. It attaches one inspector layer for each scale. In the scales that have skip connections, we attach the inspector *before* upscaling, as shown in the diagram: \n",
    "\n",
    "<img width=500 src=\"models/unetInspector.png\"/>\n",
    "\n",
    "**Attention the following code only works with images with size multiple of 16!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models import UNet\n",
    "\n",
    "class UNetInspector(nn.Module):\n",
    "    def __init__(self, unet, trainall=False):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            - unet: a unet network\n",
    "            - trainall: train the unet? (default False)\n",
    "        \"\"\"\n",
    "        super(UNetInspector, self).__init__()\n",
    "            \n",
    "        # retrieve parameters of unet network ?? any\n",
    "        self.n_channels   = unet.outc.conv.weight.shape[0] \n",
    "        self.trainall  = trainall # train the UNET \n",
    "\n",
    "        import copy\n",
    "        self.unet = copy.deepcopy(unet)\n",
    "        \n",
    "        # we don't want to train the unet parameters\n",
    "        if not trainall:\n",
    "            for p in self.unet.parameters():\n",
    "                p.requires_grad = False\n",
    "        \n",
    "        # define inspector layers\n",
    "        self.inspectors = []\n",
    "        \n",
    "\n",
    "        # then add the other inspectors from higher to lower resolutions\n",
    "        ss = [2,4,8,16]  # strides\n",
    "        kk = [4,8,16,32] # kernel sizes\n",
    "        pp = [1,2,4,8]   # padding\n",
    "        ff = [64, 128, 256, 512]   # features\n",
    "        for i in range(4):            \n",
    "#            nfeatures = min(pow(2,i)*64,512)  # DEBUG\n",
    "#           print(nfeatures, pow(2,i))         # DEBUG\n",
    "            self.inspectors.append( nn.ConvTranspose2d(\n",
    "                                      ff[i], self.n_channels, \n",
    "                                      kk[i], stride=ss[i], \n",
    "                                      padding=pp[i] ) )\n",
    "            \n",
    "            name = 'inspector%d' % i\n",
    "            self.register_parameter(name + 'weight', self.inspectors[i].weight)\n",
    "            self.register_parameter(name + 'bias'  , self.inspectors[i].bias)\n",
    "\n",
    "            \n",
    "            \n",
    "        i = 4\n",
    "        # first add sanity check inspector at the end of the network\n",
    "        self.inspectors.append( nn.Conv2d(\n",
    "                                  64, self.n_channels, \n",
    "                                  3, padding=1 ) )\n",
    "        \n",
    "        name = 'inspector%d' % i\n",
    "        self.register_parameter(name + 'weight', self.inspectors[i].weight)\n",
    "        self.register_parameter(name + 'bias'  , self.inspectors[i].bias)  \n",
    "        \n",
    "                \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # force eval mode in dncnn network\n",
    "        if not self.trainall:\n",
    "            self.unet.eval()\n",
    "\n",
    "        outputs = []        \n",
    "                \n",
    "        x1 = self.unet.inc(x)\n",
    "        x2 = self.unet.down1(x1)\n",
    "        x3 = self.unet.down2(x2)\n",
    "        x4 = self.unet.down3(x3)\n",
    "        \n",
    "        x5 = self.unet.down4(x4)\n",
    "        outputs.append( self.inspectors[3](x5) ) \n",
    "\n",
    "        x = self.unet.up1(x5, x4)\n",
    "        outputs.append( self.inspectors[2](x) ) \n",
    "\n",
    "        x = self.unet.up2(x, x3)\n",
    "        outputs.append( self.inspectors[1](x) ) \n",
    "\n",
    "        x = self.unet.up3(x, x2)        \n",
    "        outputs.append( self.inspectors[0](x) ) \n",
    "\n",
    "        x = self.unet.up4(x, x1)\n",
    "        outputs.append( self.inspectors[4](x) ) \n",
    "        \n",
    "        x = self.unet.outc(x)\n",
    "        \n",
    "        outputs.append( x ) \n",
    "\n",
    "        # returns a tensor having all the produced outputs as channels\n",
    "        # the number of channels is (num_layers-1)*ch, where ch is the \n",
    "        # number of channels of x\n",
    "        return torch.cat(outputs,-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We now train and apply the inspector networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train layer inspectors by minimizing the multi output MSE loss\n",
    "\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "from models import DnCNN\n",
    "\n",
    "sigma=30\n",
    "\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "\n",
    "if training:\n",
    "    # data\n",
    "    trainloader, valloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=128, \n",
    "                                               train_batch_size=32)\n",
    "\n",
    "    # load a dncnn network, and build an inspector for it\n",
    "    denoiser, _, trainloss, valloss = torch.load('pre-trained-tp3/Unet_l2_2000.pt', map_location=loadmap)[0:4]\n",
    "    denoiser_ins = UNetInspector(denoiser)\n",
    "\n",
    "    # run the training loop\n",
    "    denoiser_ins, losst, lossv, = trainmodel(denoiser_ins, multiOutputMSELoss, trainloader, valloader, \n",
    "                                             num_epochs=200, save_every=100, loss_every=10,  \n",
    "                                             learning_rate=0.01, weight_decay=0.0,\n",
    "                                             filename='pre-trained-tp3/layer_inspector_Unet_')\n",
    "\n",
    "else:\n",
    "    denoiser_ins, _, losst, lossv = torch.load('pre-trained-tp3/layer_inspector_Unet_0200.pt', map_location=loadmap)\n",
    "\n",
    "# plot loss\n",
    "plt.semilogy(lossv, label='val')\n",
    "plt.semilogy(losst, label='train')\n",
    "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models import DnCNN_pretrained\n",
    "from skimage import io\n",
    "from denoising_helpers import PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "# test it with a noisy image\n",
    "sigma=30\n",
    "\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32')[0:480,0:320]  #<<<<< HERE WE FOCE THE SHAPE\n",
    "\n",
    "# put the image in the range [0,1] and add noise\n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "im_noisy = im_noisy.astype('float32') / 255.\n",
    "\n",
    "# create inpector from existing dncnn\n",
    "denoiser_ins = torch.load('pre-trained-tp3/layer_inspector_Unet_0200.pt', map_location=loadmap)[0]\n",
    "\n",
    "# torch data type\n",
    "dtype = torch.FloatTensor\n",
    "if torch.cuda.is_available():\n",
    "    # run on GPU\n",
    "    denoiser_ins = denoiser_ins.cuda()\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# set denoising network in evaluation (inference) mode\n",
    "denoiser_ins.eval()\n",
    "\n",
    "# apply inspector network\n",
    "with torch.no_grad(): # tell pytorch that we don't need gradients\n",
    "    img = dtype(im_noisy[np.newaxis,np.newaxis,:,:]) # convert to tensor\n",
    "    out = denoiser_ins(img).cpu()\n",
    "\n",
    "outs = []\n",
    "for i in range(out.shape[1]):\n",
    "    outs.append( (out[0,i,:,:]*255, 'inspector %d - %f (dB)' % (i, PSNR(out[0,i,:,:]*255, im_clean)) ) )\n",
    "\n",
    "outs.append( (im_noisy*255, 'noisy - %f (dB)' % (PSNR(im_noisy, im_clean)) ) )\n",
    "\n",
    "vistools.display_gallery(unzip(outs,0), unzip(outs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question 3.** What do you observe in the above experiment. Is this what you expected? Comment on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ANSWER TO QUESTION 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# U-Net without skip connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To understand the importance of skip connections, we will train a network without them:\n",
    "\n",
    "<img width=500 src=\"models/unetX.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from models import UNet\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "\n",
    "\n",
    "\n",
    "sigma=30\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "\n",
    "# choose loss\n",
    "#loss_name = 'l1'\n",
    "loss_name = 'l2'\n",
    "\n",
    "if training:\n",
    "    \n",
    "    # data\n",
    "    trainloader, validationloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=128, \n",
    "                                               train_batch_size=45 )\n",
    "\n",
    "    # network model without skip connections\n",
    "    denoiser =  UNet(1,1, skipc=False)\n",
    "\n",
    "    # run the training loop using chosen loss\n",
    "    loss_fn = nn.L1Loss() if loss_name == 'l1' else nn.MSELoss()\n",
    "    denoiser, losst, lossv, = trainmodel(denoiser, loss_fn, trainloader, validationloader, \n",
    "                                         num_epochs=2000, save_every=250, loss_every=10,  \n",
    "                                         learning_rate=0.001, weight_decay=0.00001,\n",
    "                                         filename='pre-trained-tp3/Unet_noskip_%s_' % (loss_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import torch\n",
    "from models import UNet\n",
    "from denoising_helpers import test_denoiser\n",
    "\n",
    "\n",
    "denoiser, _, losst, lossv = torch.load('pre-trained-tp3/Unet_noskip_l2_2000.pt', map_location=loadmap)[0:4]\n",
    "plt.semilogy(losst[0:])\n",
    "plt.semilogy(lossv[0:])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "import vistools\n",
    "\n",
    "\n",
    "img_clean = io.imread('datasets/BSD68/test002.png', dtype='float32') \n",
    "#img_clean = io.imread('datasets/LIVE1/bikes.bmp', dtype='float32')[:,:,1]\n",
    "\n",
    "_=test_denoiser(denoiser, img_clean, sigma=30, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This result shouldn't be surprising. Let's look at the inspectors for the U-Net without skip connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# train layer inspectors by minimizing the multi output MSE loss\n",
    "\n",
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "from models import UNet\n",
    "\n",
    "sigma=30\n",
    "\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "\n",
    "if training:\n",
    "    # data\n",
    "    trainloader, valloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=128, \n",
    "                                               train_batch_size=32)\n",
    "\n",
    "    # load a dncnn network, and build an inspector for it\n",
    "    denoiser, _, trainloss, valloss = torch.load('pre-trained-tp3/Unet_noskip_l2_2000.pt', map_location=loadmap)[0:4]\n",
    "    denoiser_ins = UNetInspector(denoiser)\n",
    "\n",
    "    # run the training loop\n",
    "    denoiser_ins, losst, lossv, = trainmodel(denoiser_ins, multiOutputMSELoss, trainloader, valloader, \n",
    "                                             num_epochs=200, save_every=100, loss_every=10,  \n",
    "                                             learning_rate=0.01, weight_decay=0.0,\n",
    "                                             filename='pre-trained-tp3/layer_inspector_Unet_noskip_')\n",
    "\n",
    "else:\n",
    "    denoiser_ins, _, losst, lossv = torch.load('pre-trained-tp3/layer_inspector_Unet_noskip_0200.pt', map_location=loadmap)\n",
    "\n",
    "# plot loss\n",
    "plt.semilogy(lossv, label='val')\n",
    "plt.semilogy(losst, label='train')\n",
    "plt.legend(); plt.xlabel('epoch'); plt.ylabel('loss');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from models import DnCNN_pretrained\n",
    "from skimage import io\n",
    "from denoising_helpers import PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "# test it with a noisy image\n",
    "sigma=30\n",
    "im_clean = io.imread('datasets/BSD68/test002.png', dtype='float32')[0:480,0:320]\n",
    "\n",
    "# put the image in the range [0,1] and add noise\n",
    "im_noisy = im_clean + np.random.normal(0, sigma, im_clean.shape)\n",
    "im_noisy = im_noisy.astype('float32') / 255.\n",
    "\n",
    "# create inpector from existing dncnn\n",
    "denoiser_ins = torch.load('pre-trained-tp3/layer_inspector_Unet_noskip_0200.pt', map_location=loadmap)[0]\n",
    "\n",
    "# torch data type\n",
    "dtype = torch.FloatTensor\n",
    "if torch.cuda.is_available():\n",
    "    # run on GPU\n",
    "    denoiser_ins = denoiser_ins.cuda()\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "\n",
    "# set denoising network in evaluation (inference) mode\n",
    "denoiser_ins.eval()\n",
    "\n",
    "# apply inspector network\n",
    "with torch.no_grad(): # tell pytorch that we don't need gradients\n",
    "    img = dtype(im_noisy[np.newaxis,np.newaxis,:,:]) # convert to tensor\n",
    "    out = denoiser_ins(img).cpu()\n",
    "\n",
    "outs = []\n",
    "for i in range(out.shape[1]):\n",
    "    outs.append( (out[0,i,:,:]*255, 'inspector %d - %f (dB)' % (i, PSNR(out[0,i,:,:]*255, im_clean)) ) )\n",
    "\n",
    "outs.append( (im_noisy*255, 'noisy - %f (dB)' % (PSNR(im_noisy, im_clean)) ) )\n",
    "\n",
    "vistools.display_gallery(unzip(outs,0), unzip(outs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question 4.** \n",
    "Compare these results with the outputs of inpectors for the U-Net (with the skip connections). How do the skip connections alter the information encoded at each scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ANSWER TO QUESTION 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Strangled DnCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will now return to DnCNN (our default denoising network) to do an experiment. We will include, in our tiny DnCNN a strangling hidden layer with with one channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# definition of DnCNN module with added strangled layers.\n",
    "\n",
    "class CONV_BN_RELU(nn.Module):\n",
    "    '''\n",
    "    PyTorch Module grouping together a 2D CONV, BatchNorm and ReLU layers.\n",
    "    This will simplify the definition of the DnCNN network.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_channels=128, out_channels=128, kernel_size=7, \n",
    "                 stride=1, padding=3):\n",
    "        '''\n",
    "        Constructor\n",
    "\n",
    "        Args:\n",
    "            - in_channels: number of input channels from precedding layer\n",
    "            - out_channels: number of output channels\n",
    "            - kernel_size: size of conv. kernel\n",
    "            - stride: stride of convolutions\n",
    "            - padding: number of zero padding\n",
    "\n",
    "        Return: initialized module\n",
    "        '''\n",
    "        super(__class__, self).__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, \n",
    "                              stride=stride, padding=padding)\n",
    "        self.bn   = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Applies the layer forward to input x\n",
    "        '''\n",
    "        out = self.conv(x)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return(out)\n",
    "\n",
    "\n",
    "\n",
    "class StrangledDnCNN(nn.Module):\n",
    "    '''\n",
    "    PyTorch module for the DnCNN network.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, in_channels=1, out_channels=1, num_layers=17, \n",
    "                 features=64, kernel_size=3, residual=True,\n",
    "                 strangling_layers = None):\n",
    "        '''\n",
    "        Constructor\n",
    "\n",
    "        Args:\n",
    "            - in_channels: input image channels (default 1)\n",
    "            - out_channels: output image channels (default 1)\n",
    "            - num_layers: number of non-strangling layers (default 17)\n",
    "            - num_features: number of hidden features (default 64)\n",
    "            - kernel_size: size of conv. kernel (default 3)\n",
    "            - residual: use residual learning (default True)\n",
    "            - strangling_layers: indices of the layers where strangling is added\n",
    "\n",
    "        Return: initialized network\n",
    "        '''\n",
    "        super(__class__, self).__init__()\n",
    "        \n",
    "        if strangling_layers is None:\n",
    "            strangling_layers = (num_layers-2)//2\n",
    "        \n",
    "        strangling_mask = np.zeros(num_layers)\n",
    "        strangling_mask[strangling_layers] = 1\n",
    "        \n",
    "        self.residual = residual\n",
    "        \n",
    "        # a list for the layers\n",
    "        self.layers = []\n",
    "        \n",
    "        # first layer\n",
    "        self.layers.append(CONV_BN_RELU(in_channels=in_channels,\n",
    "                                        out_channels=features,\n",
    "                                        kernel_size=kernel_size,\n",
    "                                        stride=1, padding=kernel_size//2))\n",
    "        # half of intermediate layers\n",
    "        for l in range(num_layers-2):\n",
    "            self.layers.append(CONV_BN_RELU(in_channels=features,\n",
    "                                            out_channels=features,\n",
    "                                            kernel_size=kernel_size,\n",
    "                                            stride=1, padding=kernel_size//2))\n",
    "            \n",
    "            if strangling_mask[l+1]:\n",
    "                # strangling layers\n",
    "                self.layers.append(CONV_BN_RELU(in_channels=features,\n",
    "                                                out_channels=in_channels,\n",
    "                                                kernel_size=kernel_size,\n",
    "                                                stride=1, padding=kernel_size//2))\n",
    "\n",
    "                self.layers.append(CONV_BN_RELU(in_channels=in_channels,\n",
    "                                                out_channels=features,\n",
    "                                                kernel_size=kernel_size,\n",
    "                                                stride=1, padding=kernel_size//2))\n",
    "\n",
    "        # last layer \n",
    "        self.layers.append(nn.Conv2d(in_channels=features,\n",
    "                                     out_channels=out_channels,\n",
    "                                     kernel_size=kernel_size,\n",
    "                                     stride=1, padding=kernel_size//2))\n",
    "        # chain the layers\n",
    "        self.dncnn = nn.Sequential(*self.layers)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Forward operation of the network on input x.'''\n",
    "        out = self.dncnn(x)\n",
    "        \n",
    "        if self.residual: # residual learning\n",
    "            out = x - out \n",
    "        \n",
    "        return(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from denoising_dataloaders import train_val_denoising_dataloaders\n",
    "from training import trainmodel\n",
    "from models import DnCNN\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "sigma=30\n",
    "\n",
    "# DO NOT set this flag to true if running on the server.\n",
    "# The results are already pre-computed.\n",
    "training=False\n",
    "\n",
    "if training:\n",
    "    # data\n",
    "    trainloader, valloader = train_val_denoising_dataloaders(\n",
    "                                              './datasets/Train400/', \n",
    "                                               noise_sigma=sigma, crop_size=40, \n",
    "                                               train_batch_size=32 )\n",
    "\n",
    "    # network model\n",
    "    denoiser = StrangledDnCNN(in_channels=1, out_channels=1, \n",
    "                              num_layers=7,\n",
    "                              features=13,\n",
    "                              kernel_size=3, \n",
    "                              residual=True,\n",
    "                              strangling_layers=[3]) # Strangled1\n",
    "#                               strangling_layers=[2,4]) # Strangled2\n",
    "\n",
    "\n",
    "    # loss\n",
    "    loss = nn.MSELoss()\n",
    "\n",
    "    # run the training loop\n",
    "    denoiser, losst, lossv, = trainmodel(denoiser, loss, trainloader, valloader, \n",
    "                                        num_epochs=2000, save_every=1000, loss_every=200,  \n",
    "                                        learning_rate=0.01, weight_decay=0.00001,\n",
    "                                        filename='pre-trained-tp3/tiny_Strangled1_DnCNN_')\n",
    "\n",
    "else:\n",
    "    denoiser, _, losst, lossv = torch.load('pre-trained-tp3/tiny_Strangled1_DnCNN_2000.pt', map_location=loadmap)\n",
    "\n",
    "# plot loss\n",
    "plt.semilogy(lossv, label='val')\n",
    "plt.semilogy(losst, label='train')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare the denoising results\n",
    "\n",
    "from skimage import io\n",
    "from denoising_helpers import test_denoiser, PSNR\n",
    "from vistools import unzip\n",
    "\n",
    "# load denoising nets\n",
    "\n",
    "# load an image\n",
    "img_clean = io.imread('datasets/BSD68/test002.png', dtype='float32')\n",
    "img_noisy = img_clean + np.random.normal(0, sigma, img_clean.shape)\n",
    "\n",
    "outs = list()\n",
    "\n",
    "net = torch.load('pre-trained-tp2/tiny_DnCNN_2000.pt', map_location=loadmap)[0]\n",
    "out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "outs.append( (out, 'tiny DnCNN - %f (dB)' % (PSNR(out, img_clean)) ) ) \n",
    "\n",
    "net = torch.load('pre-trained-tp3/tiny_Strangled1_DnCNN_2000.pt', map_location=loadmap)[0]\n",
    "out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "outs.append( (out, 'tiny DnCNN 1 strangling layer - %f (dB)' % (PSNR(out, img_clean)) ) ) \n",
    "\n",
    "net = torch.load('pre-trained-tp3/tiny_Strangled2_DnCNN_2000.pt', map_location=loadmap)[0]\n",
    "out = test_denoiser(net, img_noisy, sigma, has_noise=True)[0]\n",
    "outs.append( (out, 'tiny DnCNN 2 stragling layers - %f (dB)' % (PSNR(out, img_clean)) ) ) \n",
    "\n",
    "outs.append( (np.array(img_clean).clip(0,255), 'clean'))\n",
    "outs.append( (np.array(img_noisy).clip(0,255), 'noisy'))\n",
    "\n",
    "vistools.display_gallery(unzip(outs,0), unzip(outs,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question 6.** What's the effect of the strangling layers in the networks performance? What would expect about the performance of the *trainable inference* networks that we saw in the theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "ANSWER TO QUESTION 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---------------------------\n",
    "[//]: # (© 2018 Gabriele Facciolo and Pablo Arias)\n",
    "[//]: # (<div style=\"text-align:center; font-size:75%;\"> Copyright © 2018 Gabriele Facciolo and Pablo Arias. All rights reserved.</div> )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
